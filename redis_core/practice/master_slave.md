# 主从切换的坑

## 一、主从数据不一致

由于主从库间的命令复制是异步进行的，可能会出现：客户端A写操作在主库执行后，该操作尚未同步到从库，客户端B就在从库读该数据，导致读到旧值。有2种原因会出现这种情况：

1. 主从库间有网络延迟，从库不能及时收到主库发送的命令，导致从库执行同步命令的时间被延后
2. 从库及时收到了主库的命令，但正在处理其他复杂度高的命令而处于阻塞中，而阻塞期间，主库可能又执行了新的写操作，主从不一致就会加剧。

### 解决方法

1. 尽量保证主从库间的网络连接状况良好（废话）
2. 开发一个外部程序来监控主从库间的复制进度，思路如下图所示：

   ```mermaid
   graph TB
   1[从主库读取master_repl_offset] --> 2[读取第i个从库的slave_repl_offset]
   2 -->3[计算复制进度差值 diff]
   3 --> 4{diff > max_offset}
   4 --是-->5[从客户端移除从库i的连接信息]
   4 --否-->6{遍历完所有从库}
   6 --是-->7[结束本轮监控]
   6 --否-->2
   ```

   监控程序一直监控着从库的复制进度，当从库的复制进度赶上主库时，才允许客户端跟这些从库连接。

## 二、读到过期数据

主要是由Redis的过期删除策略引起的

1. 惰性删除策略

   数据到了过期时间后，并不立即删除，等到下次请求该数据时，进行检查，如果发现过期了，再删除

   优点：尽量减少删除操作对CPU资源的使用，不用浪费时间定期去检查和删除了。

   缺点：浪费内存

2. 定期删除策略

   每隔一段时间（默认100ms），随机挑选一定量的数据，挑出过期的删掉。

### 为什么导致读到过期数据？

- 定期删除策略：每次随机检查的数据不多，如果过期数据很多，并且没有被访问，这些数据会保留在Redis实例中，导致从从库读到过期数据
- 惰性删除策略：从库本身不执行删除操作，如果客户端再从库中访问留存的过期数据，从库不会出发删除，会返回过期数据。**Redis3.2以后，如果读取的数据已经过期，从库虽然不会删除，但是会返回空值**

### 设置过期时间命令的影响

设置过期时间的命令有四个：

- EXPIRE和PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；
- EXPIREAT和PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点。

因为主从同步需要时间，所以建议：**在业务应用中使用EXPIREAT/PEXPIREAT命令，把数据的过期时间设置为具体的时间点，避免读到过期数据**。（主从节点的时钟要保持一致）

## 三、不合理的配置导致服务挂掉

1. **protect-mode配置项**

   限定哨兵实例能否被其他服务器访问：

   - yes：哨兵实例只能在部署的服务器本地访问
   - no：其他服务器也可以访问这个哨兵实例

   要配置成yes，并将bind配置项设置为其他哨兵实例的IP地址，避免哨兵实例间无法通讯。

   ```bash
   protected-mode no
   bind 192.168.10.3 192.168.10.4 192.168.10.5
   ```

2. **cluster-node-timeout配置项**

   这个配置项设置了Redis Cluster中实例响应心跳消息的超时时间。

   当在Redis Cluster集群中为每个实例配置了“一主一从”模式时，如果主实例发生故障，从实例会切换为主实例，受网络延迟和切换操作执行的影响，切换时间可能较长，就会导致实例的心跳超时（超出cluster-node-timeout）。实例超时后，就会被Redis Cluster判断为异常。而Redis Cluster正常运行的条件就是，有半数以上的实例都能正常运行。

   所以，如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。因此建议将cluster-node-timeout调大些（例如10到20秒）

3. **slave-serve-stale-data配置项**

   该配置项设置了从库是否能处理数据读写命令，可以将其设置为no，这样一来，从库只能服务INFO、SLAVEOF命令，就可以避免在从库中读到不一致的数据了

   需要注意的是：该配置项和slave_read_only的区别，后者是设置从库能否处理写命令，设为yes时从库只能处理读请求，无法处理写请求。

## 四、脑裂

所谓脑裂，是指在主从集群中，同时有两个主节点，他们都能接收写请求，导致客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端回望不同的节点写入数据，严重的话，会进一步导致数据丢失。

### 1. 为什么会发生脑裂？

脑裂现象最直接的表现时客户端发送的数据丢失，当数据丢失时，可进行如下排查：

1. 确认是不是数据同步出现了问题
   
   主库的数据还没同步到从库，结果主库故障了，等从库升级为主库后，未同步的数据就丢失了；

   这种情况的数据丢失，可以通过对比master_repl_offset和slave_repl_offset的差值来判断

2. 如果数据同步没问题，就排查客户端日志是否有脑裂现象
   
   主从切换后，看是否有客户端与老主库进行交互

3. 判断原主库是否假故障，假故障会导致脑裂。
   
   - 主库所在服务器的其他程序临时占用了大量资源，导致短时间无法响应心跳
   - 主库自身遇到了阻塞的情况（处理big key、内存swap等）

### 2. 为什么脑裂会导致数据丢失？

主从切换后，从库一旦升级为主库，哨兵就会让原主库执行slave of命令，和新主库进行全量同步，而在全量同步的最后阶段，原主库需要清空本地数据，加载新竹库发送的RDB文件，这样原主库在主从切换期间保存的新写数据就丢失了。

### 3. 如何应对脑裂问题？

在主从集群机制的配置项中查找是否有限制主库接收请求的设置，如：

- min-slaves-to-writes: 设置主库能进行数据同步的最少从库数量
- min-slaves-max-lag：设置了主从库间进行数据复制时，从库发给主库ACK消息的最大延迟（单位秒）

把min-slaves-to-write和min-slaves-max-lag搭配使用，分别设置一定的阈值，假设为N和T。即：主库连接的从库中至少有N个从库，和主库进行数据复制时的ACK消息延迟不能超过T秒，否则，主库就不会再接收客户端的请求了。
